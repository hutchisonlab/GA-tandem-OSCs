{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training OPEP2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is intended for users to retrain the RF/NN ensemble model, referred to as OPEP2, to predict the PCE of non-fullerene acceptor (NFA) and donor pairs for organic solar cells. Previous calculations on each acceptor and donor are required, such as GFN2-xTB, sTD-DFT-xTB, and single-point xTB for solvation in water and hexane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import DataStructs\n",
    "from numpy import linalg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd4d39-8eb8-4ea0-8122-706d15e22136",
   "metadata": {},
   "source": [
    "### Parse GFN2-xTB output file for polarizability and dipole moment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60996c6a-cce4-4095-b91e-19dece95e178",
   "metadata": {},
   "source": [
    "Polarizability is in units of $au^3$ and dipole moment is in units of Debye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7532fde-a63c-444e-981e-ddf1c0647cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_GFN2(filename, data):\n",
    "    '''\n",
    "    Parses through GFN2-xTB output files\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    filename: str\n",
    "        path to output file\n",
    "    data: list\n",
    "        list of descriptors to add to\n",
    "    '''\n",
    "    \n",
    "    with open(filename, 'r', encoding = 'utf-8') as file:\n",
    "        line = file.readline()\n",
    "        while line:\n",
    "            if 'molecular dipole' in line:\n",
    "                line = file.readline()\n",
    "                line = file.readline()\n",
    "                line = file.readline()\n",
    "                line_list = line.split()\n",
    "                dipole_moment = float(line_list[-1])\n",
    "                \n",
    "            elif 'Mol. C8AA' in line:\n",
    "                line = file.readline()\n",
    "                line_list = line.split()\n",
    "                polarizability = float(line_list[-1])\n",
    "\n",
    "            line = file.readline()  \n",
    "        line = file.readline()\n",
    "\n",
    "        outputs = [dipole_moment, polarizability]\n",
    "        data.extend(outputs)\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97186c3c-4a47-43f8-9227-d487c8d13261",
   "metadata": {},
   "source": [
    "### Parse sTD-DFT-xTB output files (*.stda) for energy levels and absorption spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9529c65a-f619-4401-86fc-dd4a8adee8a0",
   "metadata": {},
   "source": [
    "Extracts/computes the following descriptors:  \n",
    "1. HOMO (eV)\n",
    "2. HOMO-1 (eV)\n",
    "3. LUMO (eV)\n",
    "4. LUMO+1 (eV)\n",
    "5. Fundamental Band Gap (eV) (LUMO-HOMO)\n",
    "6. deltaHOMO - difference in energy between HOMO and HOMO-1 (eV)\n",
    "7. deltaLUMO - difference in energy between LUMO and LUMO+1 (eV)\n",
    "8. Optical Band Gap (eV) - energy of the first transition within the first 12 transition with an oscillator strength greater than 0.5\n",
    "9. Max abs (nm) - transition with the strongest absorption\n",
    "10. summed_oscs - Sum of oscillator strengths (unitless)\n",
    "11. area_spectra - area under the absorption spectrum curve using trapzoidal rule integration\n",
    "12. area_sim_solar_spectra - area under the curve of the simulated spectrum multiplied by the normalized solar spectrum\n",
    "13. chemical_potential (eV): $(HOMO+LUMO)/2$\n",
    "14. electrophilicity (eV): $chemical potential^2 / 2(LUMO-HOMO)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c0850a-f036-4cbc-b320-6c65745ef783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sTDA(filename, data):\n",
    "    '''\n",
    "    Parses through sTD-DFT-xTB output files\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    filename: str\n",
    "        path to output file\n",
    "    data: list\n",
    "        list of descriptors to add to\n",
    "    '''\n",
    "    with open(filename, 'r', encoding = 'utf-8') as file:\n",
    "        line = file.readline()\n",
    "        oscs = []\n",
    "        wavelength = []\n",
    "        energyEV = []\n",
    "        while line:\n",
    "            if 'ordered frontier orbitals' in line:\n",
    "                for x in range(11):\n",
    "                    line = file.readline()\n",
    "                line_list = line.split()\n",
    "                HOMOminus1 = float(line_list[1])\n",
    "                \n",
    "                line = file.readline()\n",
    "                line_list = line.split()\n",
    "                HOMO = float(line_list[1])\n",
    "                \n",
    "                line = file.readline()\n",
    "                line = file.readline()\n",
    "                line_list = line.split()\n",
    "                LUMO = float(line_list[1])\n",
    "                line = file.readline()\n",
    "                line_list = line.split()\n",
    "                LUMOplus1 = float(line_list[1])\n",
    "\n",
    "                deltaHOMO = abs(HOMOminus1 - HOMO)\n",
    "                deltaLUMO = abs(LUMO - LUMOplus1)\n",
    "                fundbg = abs(HOMO-LUMO)\n",
    "\n",
    "            elif 'excitation energies, transition moments and TDA amplitudes' in line:\n",
    "                line = file.readline()\n",
    "                line = file.readline()\n",
    "                line_list = line.split()\n",
    "                while line != '\\n':\n",
    "                    line_list = line.split()\n",
    "                    oscs.append(float(line_list[3]))\n",
    "                    wavelength.append(float(line_list[2]))\n",
    "                    energyEV.append(float(line_list[1]))\n",
    "                    line = file.readline()\n",
    "\n",
    "            line = file.readline()  \n",
    "        line = file.readline()\n",
    "        \n",
    "    chemical_potential = (HOMO + LUMO)/2\n",
    "    hardness =  LUMO - HOMO\n",
    "    # https://xtb-docs.readthedocs.io/en/latest/sp.html#global-electrophilicity-index\n",
    "    electrophilicity = chemical_potential**2 / 2*hardness\n",
    "   \n",
    "    if len(oscs) != 0:\n",
    "        summed_oscs = np.sum(oscs)\n",
    "        highest_oscs = 0.0\n",
    "        opt_bg = round(energyEV[0], 2)\n",
    "        \n",
    "        # Opt bg is the energy of the first transition within the first 12 transition with an oscillator strength greater than 0.5 \n",
    "        if len(oscs) < 12:\n",
    "            for i in range(len(oscs)):\n",
    "                if  oscs[i] > 0.5:\n",
    "                    opt_bg = round(energyEV[i], 2)\n",
    "                    break\n",
    "        else:\n",
    "            for x in range(12):\n",
    "                if  oscs[x] > 0.5:\n",
    "                    opt_bg = round(energyEV[x], 2)\n",
    "                    break\n",
    "\n",
    "        # max abs is the tallest peak in the spectrum\n",
    "        for x in range(len(oscs)):\n",
    "            if  oscs[x] > highest_oscs:\n",
    "                    highest_oscs = oscs[x]\n",
    "                    max_abs = wavelength[x]\n",
    "                    \n",
    "        # Creates full spectrum\n",
    "        (spectraEV, spectraNM, spectraIntensity) = spectra(energyEV, oscs)\n",
    "        \n",
    "        # Calculates the area under the curve using trapz rule for integration\n",
    "        area_spectra = np.trapz(spectraIntensity, spectraNM, dx=0.1, axis=- 1)\n",
    "        \n",
    "        # Calculates the area under the curve of the simulated spectrum multiplied by the normalized solar spectrum\n",
    "        area_sim_solar_spectra = solar_integrated_desc(spectraNM, spectraIntensity)\n",
    "        \n",
    "        outputs = [HOMO, HOMOminus1, LUMO, LUMOplus1, fundbg, deltaHOMO, deltaLUMO, opt_bg, max_abs, summed_oscs, area_spectra, area_sim_solar_spectra, chemical_potential, electrophilicity]\n",
    "        data.extend(outputs)\n",
    "\n",
    "        return data\n",
    "    \n",
    "    else:\n",
    "        print(filename)\n",
    "        print('something is wrong')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bdc5e4-4596-4d11-ae82-e0cd74ff404a",
   "metadata": {},
   "source": [
    "### Calculate the integration of the absorption spectra using trapezoidal integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c92fa61-1c90-4ae8-a2f4-30b30701c171",
   "metadata": {},
   "source": [
    "Multiplies the molecule's absorption spectra by the normalized solar spectrum. This new curve is then integrated with trapezoidal integration and the area if the descriptor used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1807db-8f0f-46f2-962b-6ab015927c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectra(etens, etoscs, low = 0.5, high = 10.0, resolution = 0.01, smear = 0.04):\n",
    "    \"\"\"\n",
    "    Return arrays of the energies and intensities of a Lorentzian-blurred spectrum\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    etens: list\n",
    "        list of transition energies in units of eV\n",
    "    etoscs: list\n",
    "        list of oscillator strengths\n",
    "    low: float\n",
    "        transition in eV to start spectrum at\n",
    "    high: float\n",
    "        transition in eV to end spectrum at\n",
    "    resolution: float\n",
    "        increments of eV for spectrum\n",
    "    smear: float\n",
    "        blurs intensities of peaks across 0.04 eV\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Lists of the spectra in eV, nm, and their oscillator strengths\n",
    "    \"\"\"\n",
    "    maxSlices = int((high - low) / resolution) + 1\n",
    "    peaks = len(etens)\n",
    "\n",
    "    spectraEV = []\n",
    "    spectraNM = []\n",
    "    spectraIntensity = []\n",
    "    for i in range(0, maxSlices):\n",
    "        energy = float(i * resolution + low) # units of eV\n",
    "        wavelength = energy * 1239.84193 # convert eV to nm  \n",
    "        intensity = 0.0\n",
    "\n",
    "        for trans in range(0, peaks):\n",
    "            this_smear = smear / 0.2 * (-0.046 * etoscs[trans] + 0.20)\n",
    "            deltaE = etens[trans] - energy\n",
    "            intensity = intensity + etoscs[trans] * this_smear**2 / (deltaE**2 + this_smear**2)\n",
    "\n",
    "        spectraEV.append(energy)\n",
    "        spectraNM.append(wavelength) \n",
    "        spectraIntensity.append(intensity)\n",
    "        \n",
    "    return spectraEV, spectraNM, spectraIntensity\n",
    "\n",
    "def custom_round(x, base=5):\n",
    "    return float(base * round(float(x)/base))\n",
    "\n",
    "def solar_integrated_desc(spectraNM, spectraIntensity):\n",
    "    solar = pd.read_csv('Solar_radiation_spectrum.csv', index_col = 'wavelength')\n",
    "    new_spectrum_intensities = []\n",
    "    \n",
    "    # the 1.5AM solar spectra does not have constant increments of wavelengths\n",
    "    for x in range(len(spectraNM)):\n",
    "        \n",
    "        if 280 <= spectraNM[x] < 400:\n",
    "            int_wavelength = custom_round(spectraNM[x], 0.5)\n",
    "        if 400 <= spectraNM[x] < 1700:\n",
    "            int_wavelength = custom_round(spectraNM[x], 1)\n",
    "        if 1700 <= spectraNM[x] < 1702:\n",
    "            int_wavelength = custom_round(spectraNM[x], 2)\n",
    "        if 1702 <= spectraNM[x] <=4000:\n",
    "            int_wavelength = custom_round(spectraNM[x], 5)\n",
    "\n",
    "        solar_intensity = solar.loc[int_wavelength][-1]\n",
    "        \n",
    "        new_spectrum_intensities.append(float(solar_intensity) * spectraIntensity[x])\n",
    "        \n",
    "    area_altered_spectra = np.trapz(new_spectrum_intensities, spectraNM, dx=0.1, axis=- 1)\n",
    "    \n",
    "    return area_altered_spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a039345-7f71-4174-a3ec-40fa142fc6a9",
   "metadata": {},
   "source": [
    "### Descriptor to calculate the overlap between an acceptor and donor absorption spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7340c0c9-1314-409d-8a38-67eda8d05376",
   "metadata": {},
   "source": [
    "Multiplies the simulated absorption spectra of the donor and acceptors using the sTD-DFT-xTB stda files. When multiplied, the only peaks left are where there is absorption overlap. For an ideal OSC, we want the materials to absorb in different regions to maximize the number of photons absorbed from the sun. This overlap is integrated and the area is the descriptor used for the models. Theoretically, the smaller the area, the higher the PCE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dce1330-2e85-441d-b955-8f3ee66d6d7d",
   "metadata": {},
   "source": [
    "Simpson's integration was tried but sometimes led to a negative area. Trapezoidal integration fit our type of data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb650fc-0808-4ced-a285-ac4593a8aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(acceptor, donor, data):\n",
    "    \n",
    "    with open(acceptor, 'r', encoding = 'utf-8') as file:\n",
    "        line = file.readline()\n",
    "        oscs = []\n",
    "        energyEV = []\n",
    "        while line:\n",
    "            if 'excitation energies, transition moments and TDA amplitudes' in line:\n",
    "                line = file.readline()\n",
    "                line = file.readline()\n",
    "                line_list = line.split()\n",
    "                while line != '\\n':\n",
    "                    line_list = line.split()\n",
    "                    oscs.append(float(line_list[3]))\n",
    "                    energyEV.append(float(line_list[1]))\n",
    "                    line = file.readline()\n",
    "            line = file.readline()  \n",
    "        line = file.readline()\n",
    "    \n",
    "        # Creates full spectrum\n",
    "        (acc_spectraEV, acc_spectraNM, acc_spectraIntensity) = spectra(energyEV, oscs)\n",
    "        \n",
    "    with open(donor, 'r', encoding = 'utf-8') as file:\n",
    "        line = file.readline()\n",
    "        oscs = []\n",
    "        energyEV = []\n",
    "        while line:\n",
    "            if 'excitation energies, transition moments and TDA amplitudes' in line:\n",
    "                line = file.readline()\n",
    "                line = file.readline()\n",
    "                line_list = line.split()\n",
    "                while line != '\\n':\n",
    "                    line_list = line.split()\n",
    "                    oscs.append(float(line_list[3]))\n",
    "                    energyEV.append(float(line_list[1]))\n",
    "                    line = file.readline()\n",
    "            line = file.readline()  \n",
    "        line = file.readline()\n",
    "\n",
    "        # Creates full spectrum\n",
    "        (don_spectraEV,  don_spectraNM, don_spectraIntensity) = spectra(energyEV, oscs)\n",
    "        \n",
    "    overlapped_spectra_intensities = [don_spectraIntensity[i] * acc_spectraIntensity[i] for i in range(len(don_spectraIntensity))]\n",
    "\n",
    "    area_altered_spectra = np.trapz(overlapped_spectra_intensities, don_spectraNM, dx=0.1, axis=- 1)\n",
    "\n",
    "    outputs = [area_altered_spectra]\n",
    "    \n",
    "    data.extend(outputs)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculates the number of atoms in the conjugation path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPiSystemSize(mol):\n",
    "    mol = AllChem.RemoveHs(mol)\n",
    "    AllChem.Kekulize(mol)\n",
    "    pi_systems = [pi_system(mol,x.GetIdx(),[x.GetIdx()]) for x in mol.GetAtoms()]\n",
    "    largest_pi_system = max(pi_systems, key=lambda coll: len(coll))\n",
    "    pi_system_size = len(largest_pi_system)\n",
    "    return pi_system_size\n",
    "\n",
    "def pi_system(mol, current, seen):\n",
    "    atom = mol.GetAtomWithIdx(current)\n",
    "    for neighbor in atom.GetNeighbors():\n",
    "        if (neighbor.GetIdx() not in seen) and (mol.GetBondBetweenAtoms(atom.GetIdx(),neighbor.GetIdx()).GetIsConjugated() or mol.GetBondBetweenAtoms(atom.GetIdx(),neighbor.GetIdx()).GetBondTypeAsDouble() > 1):\n",
    "            seen.append(neighbor.GetIdx())\n",
    "            pi_system(mol,neighbor.GetIdx(),seen)\n",
    "    return seen\n",
    "\n",
    "def pi_sys_size(filename, molecule, data):\n",
    "    mol = AllChem.MolFromMolFile(filename)\n",
    "    pi_size = getPiSystemSize(mol)\n",
    "    \n",
    "    outputs = [pi_size]\n",
    "\n",
    "    data.extend(outputs)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate planarity of pi system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/rdkit/rdkit/tree/master/Contrib/PBF\n",
    "\n",
    "Modified from \n",
    "J. Chem. Inf. Model. 2012, 52, 10, 2516–2525\n",
    "https://pubs.acs.org/doi/10.1021/ci300293f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetBestFitPlane(pts, weights=None):\n",
    "    # number of atoms\n",
    "    wSum = len(pts)\n",
    "    # sets the origin as the sum of the coordinates for x, y, and z\n",
    "    origin = np.sum(pts, 0)\n",
    "    # finds the average of each coordinate and sets as the origin\n",
    "    origin /= wSum\n",
    "\n",
    "    # initiates blank coordinates\n",
    "    sums = np.zeros((3, 3), np.double)\n",
    "    \n",
    "    # finds the distance of each point to origin\n",
    "    for pt in pts:\n",
    "        # finds the distance of each point to origin\n",
    "        dp = pt - origin\n",
    "        \n",
    "        # sets the 3x3 matrix\n",
    "        for i in range(3):\n",
    "            sums[i, i] += dp[i] * dp[i]\n",
    "            for j in range(i + 1, 3):\n",
    "                sums[i, j] += dp[i] * dp[j]\n",
    "                sums[j, i] += dp[i] * dp[j]\n",
    "    # Averages each number in matrix by the total number of atoms\n",
    "    sums /= wSum\n",
    "    \n",
    "    # Finds the eigenvalues and eigenvectors \n",
    "    vals, vects = linalg.eigh(sums)\n",
    "\n",
    "    # gives indices sorted from smallest to largest\n",
    "    order = np.argsort(vals)\n",
    "    \n",
    "    # smallest eigenvector\n",
    "    normal = vects[:, order[0]]    \n",
    "    \n",
    "    # sets plane coordinates\n",
    "    plane = np.zeros((4, ), np.double)\n",
    "    plane[:3] = normal\n",
    "    plane[3] = -1 * normal.dot(origin)\n",
    "    \n",
    "    return plane\n",
    "\n",
    "\n",
    "def PBFRD(mol, largest_pi_system, confId=-1):\n",
    "    conf = mol.GetConformer(confId)\n",
    "    if not conf.Is3D():\n",
    "        return 0\n",
    "    \n",
    "    pts = np.array([list(conf.GetAtomPosition(x)) for x in largest_pi_system])\n",
    "    plane = GetBestFitPlane(pts)\n",
    "    \n",
    "    #distance to point\n",
    "    denom = np.dot(plane[:3], plane[:3])\n",
    "    denom = denom**0.5\n",
    "    # add up the distance from the plane for each point:\n",
    "    res = 0.0\n",
    "    for pt in pts:\n",
    "        res += np.abs(pt.dot(plane[:3]) + plane[3])\n",
    "        \n",
    "    res /= denom\n",
    "    res /= len(pts)\n",
    "    \n",
    "    # higher the number, the less planar it is\n",
    "    return res\n",
    "\n",
    "def planarity (filename, data):\n",
    "    mol = Chem.MolFromMolFile(filename)\n",
    "    mol = Chem.RemoveHs(mol)\n",
    "    Chem.Kekulize(mol)\n",
    "    pi_systems = [pi_system(mol,x.GetIdx(),[x.GetIdx()]) for x in mol.GetAtoms()]\n",
    "    largest_pi_system = max(pi_systems, key=lambda coll: len(coll))\n",
    "\n",
    "    planarity = PBFRD(mol, largest_pi_system)\n",
    "    \n",
    "    outputs = [planarity]\n",
    "    data.extend(outputs)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDKit descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdkit_descriptors(filename, data):\n",
    "    mol = Chem.MolFromMolFile(filename)\n",
    "    num_rot_bonds = Descriptors.NumRotatableBonds(mol)\n",
    "    MolLogP = Descriptors.MolLogP(mol)\n",
    "    TPSA = Descriptors.TPSA(mol)\n",
    "    NumHAcceptors = Descriptors.NumHAcceptors(mol)\n",
    "    NumHDonors = Descriptors.NumHDonors(mol)\n",
    "    RingCount = Descriptors.RingCount(mol)\n",
    "\n",
    "    outputs = [num_rot_bonds, MolLogP, TPSA, NumHAcceptors, NumHDonors, RingCount]\n",
    "    \n",
    "    data.extend(outputs)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morgan Fingerprint Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_2_fp(array):\n",
    "    fp = DataStructs.cDataStructs.UIntSparseIntVect(len(array))\n",
    "    for ix, value in enumerate(array):\n",
    "        fp[ix] = int(value)\n",
    "    return fp\n",
    "data = []\n",
    "def morgan_fp_counts(filename, data):\n",
    "    mol = Chem.MolFromMolFile(filename)\n",
    "    fp3 = AllChem.GetHashedMorganFingerprint(mol, 2, nBits=2048)\n",
    "    array = np.zeros((0,), dtype=np.int8)\n",
    "    DataStructs.ConvertToNumpyArray(fp3, array)\n",
    "    \n",
    "    fp4 = numpy_2_fp(array)\n",
    "    \n",
    "    outputs = list(fp4)\n",
    "    \n",
    "    data.extend(outputs)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solvation energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xtb-docs.readthedocs.io/en/latest/gbsa.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solvation(filename, data):\n",
    "    with open(filename, 'r', encoding = 'utf-8') as file:\n",
    "        line = file.readline()\n",
    "        while line:\n",
    "            if '-> Gsolv' in line:\n",
    "                line_list = line.split()\n",
    "                solvation_energy = float(line_list[3])\n",
    "                break\n",
    "                \n",
    "            line = file.readline()  \n",
    "        line = file.readline()\n",
    "\n",
    "    outputs = [solvation_energy]\n",
    "        \n",
    "    data.extend(outputs)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2dc9c5-96bb-4c16-8d3c-19bf6e10f014",
   "metadata": {},
   "source": [
    "### Offsets in energy levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae714845-27a2-4270-a0ec-f7aac5a1423b",
   "metadata": {},
   "source": [
    "1. HOMO offset between donor and acceptor\n",
    "2. LUMO offset between donor and acceptor\n",
    "3. difference in energy between donor's HOMO and acceptor's LUMO (thought to be enegry of CT state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5242965d-4a45-487b-bc75-de13ee682a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_offsets(acceptor, donor, data):\n",
    "    with open(acceptor, 'r', encoding = 'utf-8') as file:\n",
    "        line = file.readline()\n",
    "        while line:\n",
    "            if 'ordered frontier orbitals' in line:\n",
    "                for x in range(12):\n",
    "                    line = file.readline()\n",
    "                line_list = line.split()\n",
    "                acc_HOMO = float(line_list[1])\n",
    "                line = file.readline()\n",
    "                line = file.readline()\n",
    "                line_list = line.split()\n",
    "                acc_LUMO = float(line_list[1])\n",
    "                break\n",
    "            line = file.readline()  \n",
    "        line = file.readline()\n",
    "        \n",
    "    with open(donor, 'r', encoding = 'utf-8') as file:\n",
    "        line = file.readline()\n",
    "        while line:\n",
    "            if 'ordered frontier orbitals' in line:\n",
    "                for x in range(12):\n",
    "                    line = file.readline()\n",
    "                line_list = line.split()\n",
    "                don_HOMO = float(line_list[1])\n",
    "                line = file.readline()\n",
    "                line = file.readline()\n",
    "                line_list = line.split()\n",
    "                don_LUMO = float(line_list[1])\n",
    "                break\n",
    "            line = file.readline()  \n",
    "        line = file.readline()\n",
    "        \n",
    "    HOMO_offset = don_HOMO - acc_HOMO\n",
    "    LUMO_offset = don_LUMO - acc_LUMO\n",
    "    DonHOMO_accLUMO = acc_LUMO - don_HOMO\n",
    "                    \n",
    "    outputs = [HOMO_offset, LUMO_offset, DonHOMO_accLUMO]\n",
    "    data.extend(outputs)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataframe with all descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make code to create new dataframe based on the experimental pairs. Then can add the HOMO offset between A and D, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the experimetnal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental = pd.read_csv('filtered_experimental_PCE_params.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['acceptor', 'donor', 'reference', 'Voc', 'Jsc', 'FF', 'PCE', 'A-HOMO', 'A-HOMOminus1', 'A-LUMO', 'A-LUMOplus1', 'A-fundbg', 'A-deltaHOMO', 'A-deltaLUMO', 'A-opt_bg', 'A-max_abs', 'A-summed_oscs', 'A-area_spectra', 'A-area_sim_solar_spectra', 'A-chemical_potential', 'A-electrophilicity', 'A-pi_sys_size', 'A-num_rot_bonds', 'A-MolLogP', 'A-TPSA', 'A-NumHAcceptors', 'A-NumHDonors', 'A-RingCount','A-planarity','A-dipole_moment', 'A-polarizability', 'A-SolvationEnergy_water', 'A-SolvationEnergy_hexane', 'D-HOMO', 'D-HOMOminus1', 'D-LUMO', 'D-LUMOplus1', 'D-fundbg', 'D-deltaHOMO', 'D-deltaLUMO', 'D-opt_bg', 'D-max_abs', 'D-summed_oscs', 'D-area_spectra', 'D-area_sim_solar_spectra', 'D-chemical_potential', 'D-electrophilicity', 'D-pi_sys_size', 'D-num_rot_bonds', 'D-MolLogP', 'D-TPSA', 'D-NumHAcceptors', 'D-NumHDonors', 'D-RingCount',  'D-planarity','D-dipole_moment', 'D-polarizability', 'D-SolvationEnergy_water', 'D-SolvationEnergy_hexane', 'AD-overlap', 'AD-HOMOoffset', 'AD-LUMOoffset', 'DHOMO_ALUMO_offset']\n",
    "\n",
    "# add column names for 2048 bit morgan fingerprints\n",
    "for x in range(2048):\n",
    "    col_name = 'A-ECFP_' + str(x)\n",
    "    column_names.append(col_name)\n",
    "for x in range(2048):\n",
    "    col_name = 'D-ECFP_' + str(x)\n",
    "    column_names.append(col_name)\n",
    "\n",
    "data = pd.DataFrame(columns = column_names)\n",
    "\n",
    "for x in range(len(experimental)):\n",
    "    try:\n",
    "    \n",
    "        data = []\n",
    "\n",
    "        acceptor = experimental.iloc[x][1]\n",
    "        donor = experimental.iloc[x][2]\n",
    "        reference = experimental.iloc[x][4]\n",
    "        Voc = experimental.iloc[x][5]\n",
    "        Jsc = experimental.iloc[x][6]\n",
    "        FF = experimental.iloc[x][7]\n",
    "        PCE = experimental.iloc[x][8]\n",
    "\n",
    "        data.extend([acceptor, donor, reference, Voc, Jsc, FF, PCE])\n",
    "\n",
    "        \n",
    "        # paths to the GFN2-xTB, sTD-DFT-xTB, and xTB calculations\n",
    "        acc_stda = '../Calculations/acceptors/sTDDFT-xTB/' + acceptor + '.stda'\n",
    "        acc_mol = '../Calculations/acceptors/GFN2/' + acceptor + '.mol'\n",
    "        acc_GFN2 = '../Calculations/acceptors/GFN2/' + acceptor + '.out'\n",
    "        acc_solv_water = '../Calculations/acceptors/xtb_solvation_water/' + acceptor + '.out'\n",
    "        acc_solv_hexane = '../Calculations/acceptors/xtb_solvation_hexane/' + acceptor + '.out'\n",
    "        don_stda = '../Calculations/donors/sTDDFT-xTB/' + donor + '.stda'\n",
    "        don_mol = '../Calculations/donors/GFN2/' + donor + '.mol'\n",
    "        don_GFN2 = '../Calculations/donors/GFN2/' + donor + '.out'\n",
    "        don_solv_water = '../Calculations/donors/xtb_solvation_water/' + donor + '.out'\n",
    "        don_solv_hexane = '../Calculations/donors/xtb_solvation_hexane/' + donor + '.out'\n",
    "\n",
    "        # parse sTDDFT-xtb output files of acceptors\n",
    "        parse_sTDA(acc_stda, acceptor, data) #HOMO, HOMOminus1, LUMO, LUMOplus1, fundbg, deltaHOMO, deltaLUMO, opt_bg, max_abs, summed_oscs, area_spectra, area_sim_solar_spectra, chemical_potential, electrophilicity\n",
    "\n",
    "        # parse GFN2-xtb files for acceptor\n",
    "        pi_sys_size(acc_mol, acceptor, data) #pi_size\n",
    "        rdkit_descriptors(acc_mol, data) #num_rot_bonds, MolLogP, TPSA, NumHAcceptors, NumHDonors\n",
    "        planarity(acc_mol, data) # planarity\n",
    "\n",
    "        # calculate pi system size of acceptor\n",
    "        parse_GFN2(acc_GFN2, acceptor, data) #dipole_moment, polarizability\n",
    "\n",
    "        # calculate solvation free energy of acceptor in water\n",
    "        solvation(acc_solv_water, data) #solvation_energy\n",
    "\n",
    "        # calculate solvation free energy of acceptor in hexane\n",
    "        solvation(acc_solv_hexane, data) #solvation_energy\n",
    "\n",
    "        # parse sTDDFT-xtb output files of donors\n",
    "        parse_sTDA(don_stda, donor, data) #HOMO, HOMOminus1, LUMO, LUMOplus1, fundbg, deltaHOMO, deltaLUMO, opt_bg, max_abs, summed_oscs, area_spectra, area_sim_solar_spectra, chemical_potential, electrophilicity\n",
    "\n",
    "        # parse GFN2-xtb files for donor\n",
    "        pi_sys_size(don_mol, donor, data) #pi_size\n",
    "        rdkit_descriptors(don_mol, data) #num_rot_bonds, MolLogP, TPSA, NumHAcceptors, NumHDonors\n",
    "        planarity(don_mol, data) # planarity\n",
    "\n",
    "        # calculate pi system size of donor\n",
    "        parse_GFN2(don_GFN2, donor, data) #dipole_moment, polarizability\n",
    "\n",
    "        # calculate solvation free energy of donor in water\n",
    "        solvation(don_solv_water, data) #solvation_energy\n",
    "\n",
    "        # calculate solvation free energy of donor in hexane\n",
    "        solvation(don_solv_hexane, data) #solvation_energy\n",
    "\n",
    "        # calculate overlap between acceptor and donor\n",
    "        overlap(acc_stda, don_stda, data) #area_altered_spectra\n",
    "\n",
    "        # Energy offsets between donor and acceptor\n",
    "        energy_offsets(acc_stda, don_stda, data)\n",
    "        \n",
    "        # For morgan fingerprint counts\n",
    "        morgan_fp_counts(acc_mol, data)\n",
    "        morgan_fp_counts(don_mol, data)\n",
    "        \n",
    "\n",
    "        data.loc[len(data.index)] = data\n",
    "        \n",
    "    except:\n",
    "        print(acceptor)\n",
    "        print(donor)\n",
    "        continue\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training OPEP2 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of donor-acceptor pairs is: ' + str(len(data)))\n",
    "\n",
    "data_highPCE = data[data['PCE'] > 10]\n",
    "print('Number of donor-acceptor pairs with a PCE greater than 10% is: ' + str(len(data_highPCE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first stanardize the descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unstandardized = data_highPCE.iloc[:, 8:64]\n",
    "y = data_highPCE.iloc[:, 7:8]\n",
    "\n",
    "#standardize\n",
    "x_labels = X_unstandardized.columns\n",
    "scaler = StandardScaler().fit(X_unstandardized[x_labels]) \n",
    "X_unstandardized[x_labels] = scaler.transform(X_unstandardized[x_labels])\n",
    "\n",
    "fps = data_highPCE.iloc[:,64:]\n",
    "X = pd.concat([X_unstandardized, fps], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will randomly split the dataset into 80% training and 20% testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we will evaluate the performance of the model, using cross-validation to calculate R2, MAE, and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_metrics(model, X, y, cv=5):\n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring = 'r2')\n",
    "    SEM_r2 = round((score.std() / math.sqrt(5)) , 2)\n",
    "    r2 = round(float(score.mean()), 2)\n",
    "    print('R^2: ' + str(r2) + ' +/- ' +  str(SEM_r2))\n",
    "    \n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring = 'neg_mean_absolute_error')\n",
    "    score = np.multiply(score, -1)\n",
    "    SEM_MAE = round((score.std() / math.sqrt(5)) , 2)\n",
    "    MAE = round(score.mean(), 2) \n",
    "    print('MAE: ' + str(MAE) + ' +/- ' +  str(SEM_MAE))\n",
    "    \n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring = 'neg_mean_squared_error')\n",
    "    score = np.sqrt(score * -1)\n",
    "    SEM_RMSE = round((score.std() / math.sqrt(5)) , 2)\n",
    "    RMSE = round(score.mean(), 2)\n",
    "    print('RMSE: ' + str(RMSE) + ' +/- ' +  str(SEM_RMSE))\n",
    "    \n",
    "    return r2, SEM_r2, RMSE, SEM_RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we will train the model. The hyperparameter tuning was previously performed in a separate notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model =RandomForestRegressor(n_estimators=80,max_depth=8, min_samples_split=2, min_samples_leaf=2, max_features=57, random_state=20)\n",
    "ann_model = MLPRegressor(hidden_layer_sizes = (50, 50, 50), learning_rate = 'adaptive', random_state=14, max_iter=500)\n",
    "\n",
    "em_rf_ann = VotingRegressor([('rf', rf_model), ('ann', ann_model)])\n",
    "em_rf_ann.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "print('training set')\n",
    "R2_train, R2_SEM_train, RMSE_train, RMSE_SEM_train = model_metrics(em_rf_ann, x_train, y_train, cv=5)\n",
    "print('test set')\n",
    "R2_test, R2_SEM_test, RMSE_test, RMSE_SEM_test = model_metrics(em_rf_ann, x_test, y_test, cv=5)\n",
    "\n",
    "em_rf_ann_predictions_test = em_rf_ann.predict(x_test)\n",
    "em_rf_ann_predictions_train = em_rf_ann.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the predictions vs experimental:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (5.5, 5))\n",
    "ax.scatter(em_rf_ann_predictions_train, y_train, color = '#882255')\n",
    "ax.scatter(em_rf_ann_predictions_test, y_test, color = '#44AA99')\n",
    "\n",
    "# x=y line\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()])]  # max of both axes\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "\n",
    "ax.set_ylabel('Experimental PCE (%)', labelpad=10, weight='bold', size=16)\n",
    "ax.set_xlabel('Predicted PCE (%)', labelpad=10, weight='bold', size=16)\n",
    "ax.tick_params(axis = 'x', labelsize=14)\n",
    "ax.tick_params(axis = 'y', labelsize=14)\n",
    "\n",
    "text_train = 'Training Set\\n$R^2$=' + str(R2_train) + '$\\pm$' + str(R2_SEM_train) + '\\nRMSE=' + str(RMSE_train)+ '$\\pm$' + str(RMSE_SEM_train)\n",
    "text_test = 'Test Set\\n$R^2$=' + str(R2_test) + '$\\pm$' + str(R2_SEM_test) + '\\nRMSE=' + str(RMSE_test)+ '$\\pm$' + str(RMSE_SEM_test)\n",
    "\n",
    "ax.text(15.4, 11.5, text_train, ha='left', size=13, color='#882255')\n",
    "ax.text(15.4, 9.5, text_test, ha='left', size=13, color='#44AA99')\n",
    "ax.set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea8f6b8185cedd5266ce889df578ed731f76868fbab925aa978fea8da140e284"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
